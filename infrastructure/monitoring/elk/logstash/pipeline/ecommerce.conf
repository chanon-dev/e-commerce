input {
  # Application logs from Docker containers
  beats {
    port => 5044
  }
  
  # Kafka logs for real-time processing
  kafka {
    bootstrap_servers => "kafka-1:9092,kafka-2:9093,kafka-3:9094"
    topics => ["application-logs", "audit-logs", "security-logs"]
    group_id => "logstash-ecommerce"
    consumer_threads => 3
    codec => json
  }
  
  # Syslog for infrastructure logs
  syslog {
    port => 5514
    type => "syslog"
  }
  
  # HTTP input for webhook logs
  http {
    port => 8080
    type => "webhook"
  }
}

filter {
  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }
  
  # Add common fields
  mutate {
    add_field => {
      "[@metadata][environment]" => "${ENVIRONMENT:development}"
      "[@metadata][platform]" => "ecommerce"
    }
  }
  
  # Service-specific parsing
  if [container_name] {
    # Extract service name from container name
    grok {
      match => { "container_name" => "ecommerce-(?<service_name>[^-]+)-.*" }
    }
    
    # Auth Service logs
    if [service_name] == "auth" {
      if [message] =~ /login/ {
        grok {
          match => { 
            "message" => "User %{DATA:user_id} login %{WORD:login_status} from %{IP:client_ip}" 
          }
        }
        
        if [login_status] == "failed" {
          mutate {
            add_tag => ["security", "failed_login"]
            add_field => { "alert_level" => "warning" }
          }
        }
      }
      
      if [message] =~ /suspicious/ {
        mutate {
          add_tag => ["security", "suspicious_activity"]
          add_field => { "alert_level" => "critical" }
        }
      }
    }
    
    # Order Service logs
    if [service_name] == "order" {
      if [message] =~ /order created/ {
        grok {
          match => { 
            "message" => "Order %{DATA:order_id} created for user %{DATA:user_id} amount %{NUMBER:order_amount}" 
          }
        }
        
        mutate {
          add_tag => ["business", "order_created"]
          convert => { "order_amount" => "float" }
        }
      }
      
      if [message] =~ /payment failed/ {
        grok {
          match => { 
            "message" => "Payment failed for order %{DATA:order_id} reason %{DATA:failure_reason}" 
          }
        }
        
        mutate {
          add_tag => ["business", "payment_failed"]
          add_field => { "alert_level" => "warning" }
        }
      }
    }
    
    # Product Service logs
    if [service_name] == "product" {
      if [message] =~ /inventory low/ {
        grok {
          match => { 
            "message" => "Low inventory alert for product %{DATA:product_id} quantity %{NUMBER:quantity}" 
          }
        }
        
        mutate {
          add_tag => ["business", "low_inventory"]
          add_field => { "alert_level" => "warning" }
          convert => { "quantity" => "integer" }
        }
      }
    }
    
    # Payment Service logs
    if [service_name] == "payment" {
      if [message] =~ /fraud detected/ {
        grok {
          match => { 
            "message" => "Fraud detected for transaction %{DATA:transaction_id} user %{DATA:user_id}" 
          }
        }
        
        mutate {
          add_tag => ["security", "fraud_detected"]
          add_field => { "alert_level" => "critical" }
        }
      }
    }
  }
  
  # Parse HTTP access logs
  if [type] == "nginx" {
    grok {
      match => { 
        "message" => "%{COMBINEDAPACHELOG}" 
      }
    }
    
    # Extract additional fields
    if [request] {
      grok {
        match => { "request" => "%{WORD:http_method} %{URIPATH:http_path}(?:%{URIPARAM:http_params})? HTTP/%{NUMBER:http_version}" }
      }
    }
    
    # Categorize by response code
    if [response] {
      if [response] >= 400 and [response] < 500 {
        mutate {
          add_tag => ["http_4xx"]
          add_field => { "alert_level" => "warning" }
        }
      }
      
      if [response] >= 500 {
        mutate {
          add_tag => ["http_5xx"]
          add_field => { "alert_level" => "critical" }
        }
      }
    }
  }
  
  # Parse database logs
  if [type] == "postgresql" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:pid}\] %{WORD:log_level}: %{GREEDYDATA:log_message}" 
      }
    }
    
    # Detect slow queries
    if [log_message] =~ /duration:/ {
      grok {
        match => { 
          "log_message" => "duration: %{NUMBER:query_duration:float} ms" 
        }
      }
      
      if [query_duration] and [query_duration] > 1000 {
        mutate {
          add_tag => ["slow_query"]
          add_field => { "alert_level" => "warning" }
        }
      }
    }
  }
  
  # Security log parsing
  if "security" in [tags] {
    # Parse IP geolocation
    if [client_ip] {
      geoip {
        source => "client_ip"
        target => "geoip"
      }
    }
    
    # Add security context
    mutate {
      add_field => {
        "security_event" => "true"
        "requires_investigation" => "true"
      }
    }
  }
  
  # Business metrics extraction
  if "business" in [tags] {
    mutate {
      add_field => {
        "business_metric" => "true"
        "dashboard_category" => "business"
      }
    }
  }
  
  # Performance metrics
  if [response_time] {
    if [response_time] > 2000 {
      mutate {
        add_tag => ["slow_response"]
        add_field => { "alert_level" => "warning" }
      }
    }
  }
  
  # Clean up fields
  mutate {
    remove_field => ["beat", "offset", "prospector", "input", "source"]
  }
  
  # Add timestamp
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss" ]
    target => "@timestamp"
  }
}

output {
  # Main Elasticsearch cluster
  elasticsearch {
    hosts => ["elasticsearch-1:9200", "elasticsearch-2:9200", "elasticsearch-3:9200"]
    index => "ecommerce-logs-%{+YYYY.MM.dd}"
    template_name => "ecommerce-logs"
    template => "/usr/share/logstash/templates/ecommerce-template.json"
    template_overwrite => true
    
    # Use service name for routing
    routing => "%{service_name}"
  }
  
  # Security logs to separate index
  if "security" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch-1:9200", "elasticsearch-2:9200", "elasticsearch-3:9200"]
      index => "security-logs-%{+YYYY.MM.dd}"
      template_name => "security-logs"
      template => "/usr/share/logstash/templates/security-template.json"
      template_overwrite => true
    }
  }
  
  # Business metrics to separate index
  if "business" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch-1:9200", "elasticsearch-2:9200", "elasticsearch-3:9200"]
      index => "business-metrics-%{+YYYY.MM.dd}"
      template_name => "business-metrics"
      template => "/usr/share/logstash/templates/business-template.json"
      template_overwrite => true
    }
  }
  
  # Critical alerts to Kafka for real-time processing
  if [alert_level] == "critical" {
    kafka {
      bootstrap_servers => "kafka-1:9092,kafka-2:9093,kafka-3:9094"
      topic_id => "critical-alerts"
      codec => json
    }
  }
  
  # Debug output for development
  if [@metadata][environment] == "development" {
    stdout {
      codec => rubydebug
    }
  }
  
  # Metrics output to Prometheus
  if [business_metric] == "true" {
    http {
      url => "http://prometheus-pushgateway:9091/metrics/job/logstash-business-metrics"
      http_method => "post"
      format => "message"
      message => "business_metric{service=\"%{service_name}\",type=\"%{business_metric_type}\"} %{metric_value} %{[@timestamp]}"
    }
  }
}
